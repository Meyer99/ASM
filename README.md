# Compilers Review

- [Compilers Review](#Compilers-Review)
  - [Introduction](#Introduction)
  - [Lexical Analysis](#Lexical-Analysis)
    - [Regular Expression](#Regular-Expression)
    - [NFA, DFA](#NFA-DFA)
  - [Syntax Analysis](#Syntax-Analysis)
    - [Context-free grammar](#Context-free-grammar)
    - [Top-Down Parsing](#Top-Down-Parsing)

## Introduction
* Compilers are computer programs that translate programs from one language to another
* $source\ program \to Compiler \to target\ program$  
  $input \to target\ program \to ouput$  
  input: usually written in high-level language  
  output: usually object code for the target machine (such as machine code, assembly language)
* Interpreter executes the source program during translation  
  $source\ program + input \to Interpreter \to output$
* *Phases of a compiler*:
  * Lexical analysis (scanning): identify logical pieces of character stream, output token stream
  * Syntax analysis (parsing): input token stream, output syntax tree, identify how tokens are related to each other
  * Semantic analysis: identify the meaning of the overall structure, output syntax tree with attribute assigned
  * IR generation: design one possible structure, input syntax tree, output imtermediate representation
  * ***Above is the <u>front end</u> of a compiler***  
    ***Below is the <u>back end</u> of a compiler***
  * IR optimization: simplify the intended structure, machine-independently
  * Code generation: input IR, output target-machine code, fabricate the structure
  * Optimization: imporve the resulting structure

## Lexical Analysis
* A *token* is a pair consisting of a token name and an optional attribute value. For example, <**id**, foo>, <**number**, 2>, <**assign_op**>
* $source\ program \to Lexical\ Analyzer\ \underrightarrow{token}\  Parser$
* Goal: partition the input string into lexemes, identify the token of each lexeme
* left-to-right scan, lookahead sometimes required

### Regular Expression
* *Operations on language*:
  * Union: $L\cup M$
  * Concatenation: $LM$
  * Kleene closure: $L^*$
  * Positive closure: $L^+$
* *Lexical specifications*:
  * $digit \to [\text{0-9}]$
  * $digits \to digit^+$
  * $letter \to [\text{A-Za-z}]$
  * $number \to digits(.\ digits)?\ (\text{E}[+-]?\ digits)?$
  * $if \to \text{if}$
* *Notation*:
  * At least one: $\text{A}\equiv \text{AA}^*$
  * Union: $\text{A}|\text{B}$
  * Option: $\text{A}?\equiv \text{A}|\epsilon$
  * Excluded range: $[\text{\^ a-z}]$
* Precedence: parentheses, closure, concatenation, union
* Maximum munch: match as long as possible

### NFA, DFA
* Nondeterministic finite automata: no restrictions on the labels of their edges, $\epsilon$ is a possible label
* Deterministic finite automata: for each state, and for each symbol of its input alphabet, exactly one edge with that symbol leaving that state
* Convert a regular expression to an NFA: McNaughton-Yamada-Thompson alogorithm (page 159)
* An NFA may be in many states at any time
* *Subset construction of a DFA from an NFA*: (page 153)
  * $\epsilon-closure$
  * $move(T,a)$: Set of NFA states to which there is a transition on input symbol $a$ from some state $s$ in $T$
  * start state: $\epsilon-closure(s_0)$
  * accepting states: states that include at least one accepting state of NFA
  * $Dtran[T,a]=\epsilon-closure(move(T,a))$
* Giving any DFA, there is an equivalent DFA containing a minimum number of states, and this minimum-state DFA is unique
* State $s$ and $t$ are equivalent iff:
  * $s$ and $t$ are both accepting states or both non-accepting state
  * For each character $\text{a}\in \Sigma$, $s$ and $t$ have transitions on $\text{a}$ to the equivalent states
* Minimizing the number of states of a DFA: page 181
  * split the set of states into accpeting states and non-accpeting states
  * continue to split until no partition can be done

## Syntax Analysis

### Context-free grammar
* sentential form of $G$: may contain both terminals and nonterminals, and may be empty
* sentence of $G$: a sentential form with no nonterminals
* language generated by a grammar is its set of sentences
* *Parse tree*: 
  * built from *derivations*
  * nonterminals at the interior nodes, terminals at leaves
  * in-order traversal or the leaves is the original input
  * show the association of operations, while the input string does not
* Leftmost derivation: at each step, replace the leftmost nonterminal
* The rightmost and leftmost derivations have the *sam*e parse tree
* A grammar that produces more than one parse tree for some sentence is said to be *ambiguous*. Equivalently, there is more than one leftmost derivation or more than one rightmost derivation for the same sentence
* *Abstract syntax tree (AST)*:
  * similar to parse tree but ignore some details
  * operators appear at internal nodes, not at leaves
* *Left recursion*:
  * A grammar is *left recursive* if it has a nonterminal $A$ such that there is a derivation $A\xRightarrow{+}A\alpha$ for some string $\alpha$
  * Elimination of left recursion:
    * $A\to A\alpha_1\ |\ A\alpha_2\ |\ ...\ |\ A\alpha_m\ |\ \beta_1\ |\ \beta_2\ |\ ...\ |\ \beta_n$
    * $A\to \beta_1A'\ |\ \beta_2A'\ |\ ...\ |\ \beta_nA'$  
      $A'\to \alpha_1A'\ |\ \alpha_2A'\ |\ ...\ |\ \alpha_mA'\ |\ \epsilon$
  * left recursion may be not immediate
* *Left factoring*:
  * $\alpha \neq \epsilon$ and $A\to \alpha\beta_1\ |\ \alpha\beta_2\ |\ ...\ |\ \alpha\beta_n\ |\ \gamma$
  * $A\to \alpha A'\ |\ \gamma$  
    $A' \to \beta_1\ |\ \beta_2\ |\ ...\ |\ \beta_n$

### Top-Down Parsing
* *Predictive parsing*:
  * LL(*K*) grammar: left to right scanning, leftmost derivation, *k* lookahead tokens
  * In LL(1), only one choice of production at each step, backtracking is not used
  * If a grammar has either left factor or left recursion, or both, then it must be non-LL(1) grammar, but not vice versa

* *FIRST set*:
  * $FIRST(X)=\{t\ |\ X\xRightarrow{*}t\alpha\}\cup\{\epsilon\ |\ X\xRightarrow{*}\epsilon\}$
  * Algorithm for computing FIRST set: page 221
